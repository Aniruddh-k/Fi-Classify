{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9imMlrwrdUvy",
        "outputId": "ba82ef1e-c8e2-4928-a2f7-1561081062b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vaclavpechtor/rvl-cdip-small-200?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 294M/294M [00:10<00:00, 28.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"vaclavpechtor/rvl-cdip-small-200\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "beciJYTWdr1e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import time"
      ],
      "metadata": {
        "id": "dXDSbApHduC1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # convert 1 channel to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)  # normalize for 3 channels\n",
        "])"
      ],
      "metadata": {
        "id": "52PzkkiYdyVd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_transforms = transforms.Compose([\n",
        "#     transforms.Grayscale(num_output_channels=3),\n",
        "#     transforms.RandomResizedCrop(224),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(10),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# val_transforms = transforms.Compose([\n",
        "#     transforms.Grayscale(num_output_channels=3),\n",
        "#     transforms.Resize(256),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])"
      ],
      "metadata": {
        "id": "IKDzDdY4jLk0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1/rvl-cdip-small-200/train'\n",
        "val_dir = '/root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1/rvl-cdip-small-200/val'\n",
        "\n",
        "train_data = ImageFolder(train_dir, transform=transform)\n",
        "val_data = ImageFolder(val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)"
      ],
      "metadata": {
        "id": "HWOjz2Tfd0vN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "# Load pretrained model\n",
        "weights = EfficientNet_B0_Weights.DEFAULT\n",
        "model = efficientnet_b0(weights=weights)\n",
        "\n",
        "# Modify the classifier for 16 classes\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 16)\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "HgxDrMnld2_V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)"
      ],
      "metadata": {
        "id": "Mz383iJ7eD3N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "patience = 5\n",
        "best_val_acc = 0.0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_corrects.double() / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_running_corrects = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_running_corrects += torch.sum(preds == labels.data)\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_running_corrects.double() / val_total\n",
        "    print(f\"Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Scheduler step\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    # Check for improvement\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        epochs_no_improve = 0\n",
        "        print(\"Validation accuracy improved, saving model.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement in val acc for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "    if epochs_no_improve == patience:\n",
        "        print(f\"Early stopping after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouz5AVe0etN9",
        "outputId": "9434b7bc-d40b-405e-9539-52874f2b7f5b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 1.8261 Acc: 0.5215\n",
            "Val Accuracy: 0.6031\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 1.6333 Acc: 0.5813\n",
            "Val Accuracy: 0.6531\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 1.5899 Acc: 0.6043\n",
            "Val Accuracy: 0.6531\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 1.5068 Acc: 0.6230\n",
            "Val Accuracy: 0.6594\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 1.5079 Acc: 0.6379\n",
            "Val Accuracy: 0.6531\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 1.4438 Acc: 0.6508\n",
            "Val Accuracy: 0.6594\n",
            "No improvement in val acc for 2 epoch(s).\n",
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 1.4354 Acc: 0.6602\n",
            "Val Accuracy: 0.6625\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 1.4422 Acc: 0.6586\n",
            "Val Accuracy: 0.6641\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 1.4276 Acc: 0.6586\n",
            "Val Accuracy: 0.6734\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 1.3903 Acc: 0.6688\n",
            "Val Accuracy: 0.6766\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 11/20\n",
            "Train Loss: 1.4063 Acc: 0.6813\n",
            "Val Accuracy: 0.6734\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 12/20\n",
            "Train Loss: 1.4017 Acc: 0.6949\n",
            "Val Accuracy: 0.6766\n",
            "No improvement in val acc for 2 epoch(s).\n",
            "\n",
            "Epoch 13/20\n",
            "Train Loss: 1.3938 Acc: 0.6844\n",
            "Val Accuracy: 0.6734\n",
            "No improvement in val acc for 3 epoch(s).\n",
            "\n",
            "Epoch 14/20\n",
            "Train Loss: 1.3818 Acc: 0.6824\n",
            "Val Accuracy: 0.6750\n",
            "No improvement in val acc for 4 epoch(s).\n",
            "\n",
            "Epoch 15/20\n",
            "Train Loss: 1.3784 Acc: 0.6801\n",
            "Val Accuracy: 0.6703\n",
            "No improvement in val acc for 5 epoch(s).\n",
            "Early stopping after 15 epochs.\n",
            "Best validation accuracy: 0.6766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'efficientnet_b0_rvl_cdip_small_200.pth')"
      ],
      "metadata": {
        "id": "rwPQxboZe2ul"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# To store true and predicted labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Generate classification report\n",
        "target_names = [str(i) for i in range(16)]  # assuming 16 document classes in RVL-CDIP\n",
        "report = classification_report(all_labels, all_preds, target_names=target_names)\n",
        "\n",
        "print(\"ðŸ“„ Classification Report:\\n\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2FKotaWibTt",
        "outputId": "0d53b908-4092-4c4e-b0be-e5817dd1b16e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“„ Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76        40\n",
            "           1       0.69      0.55      0.61        40\n",
            "           2       0.95      0.88      0.91        40\n",
            "           3       0.84      0.90      0.87        40\n",
            "           4       0.48      0.62      0.54        40\n",
            "           5       0.76      0.93      0.83        40\n",
            "           6       0.51      0.50      0.51        40\n",
            "           7       0.67      0.70      0.68        40\n",
            "           8       0.73      0.80      0.76        40\n",
            "           9       0.97      0.72      0.83        40\n",
            "          10       0.63      0.65      0.64        40\n",
            "          11       0.57      0.53      0.55        40\n",
            "          12       0.74      0.93      0.82        40\n",
            "          13       0.80      0.70      0.75        40\n",
            "          14       0.34      0.30      0.32        40\n",
            "          15       0.80      0.70      0.75        40\n",
            "\n",
            "    accuracy                           0.70       640\n",
            "   macro avg       0.70      0.70      0.70       640\n",
            "weighted avg       0.70      0.70      0.70       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pretrained model architecture exactly like during training\n",
        "model = models.efficientnet_b0(pretrained=False)  # pretrained=False because you load weights manually\n",
        "\n",
        "# Replace the final layer if you did during training (adjust number of classes accordingly)\n",
        "num_classes = 16  # change to your number of classes\n",
        "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "# Load your saved weights\n",
        "model.load_state_dict(torch.load('/content/efficientnet_b0_rvl_cdip_small_200.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the same transform as training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # convert grayscale to 3-channel\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Load and transform the image\n",
        "img_path = '/content/Sample-handwritten-text-from-CVL-Database.png'\n",
        "img = Image.open(img_path).convert('L')  # convert to grayscale if original is not\n",
        "img_tensor = transform(img).unsqueeze(0).to(device)  # add batch dimension and move to device\n",
        "\n",
        "# Prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(img_tensor)\n",
        "    pred_class = torch.argmax(outputs, dim=1).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Y9h1Bmitfl",
        "outputId": "eab60ffd-c518-4883-e3a3-218b788761ba"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=\"/root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1/rvl-cdip-small-200/train\")\n",
        "print(train_dataset.class_to_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEhHuS5io3kM",
        "outputId": "8eca6a12-4e73-4a85-c2d9-ab907a594814"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'advertisement': 0, 'budget': 1, 'email': 2, 'file_folder': 3, 'form': 4, 'handwritten': 5, 'invoice': 6, 'letter': 7, 'memo': 8, 'news_article': 9, 'presentation': 10, 'questionnaire': 11, 'resume': 12, 'scientific_publication': 13, 'scientific_report': 14, 'specification': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_class = {v: k for k, v in train_dataset.class_to_idx.items()}"
      ],
      "metadata": {
        "id": "ab8mGGMMtelC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label = idx_to_class[pred_class]"
      ],
      "metadata": {
        "id": "BSlFyvKuuZbF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vam0NDHUucz8",
        "outputId": "0a5a6b9f-e941-4fbb-b9a9-1fe2a8015541"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "presentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwsJ_hohugyN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}