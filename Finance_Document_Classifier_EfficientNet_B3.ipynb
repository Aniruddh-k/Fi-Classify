{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DUgL7rXT2Sa",
        "outputId": "b89f98ab-2a53-4e21-95e4-1af9e0cbf389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vaclavpechtor/rvl-cdip-small-200?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 294M/294M [00:15<00:00, 20.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"vaclavpechtor/rvl-cdip-small-200\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "Mx7Qr5QKT9dv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import time"
      ],
      "metadata": {
        "id": "fJ6KSfmIUkZ9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # convert 1 channel to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)  # normalize for 3 channels\n",
        "])"
      ],
      "metadata": {
        "id": "OgygsJNPT-__"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1/rvl-cdip-small-200/train'\n",
        "val_dir = '/root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1/rvl-cdip-small-200/val'\n",
        "\n",
        "train_data = ImageFolder(train_dir, transform=transform)\n",
        "val_data = ImageFolder(val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)"
      ],
      "metadata": {
        "id": "aNsdaNzzUBLC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
        "\n",
        "# Load pretrained model\n",
        "weights = EfficientNet_B3_Weights.DEFAULT\n",
        "model = efficientnet_b3(weights=weights)\n",
        "\n",
        "# Modify the classifier for 16 classes\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 16)\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bli4XHOjUEf2",
        "outputId": "a832d2bb-1cb6-48bb-b5ae-b03f8a1585fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
            "100%|██████████| 47.2M/47.2M [00:00<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, weight_decay=1e-4)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HDcW49LUMqu",
        "outputId": "61326006-f7e5-4bef-c1b1-5a47699a92cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "patience = 5\n",
        "best_val_acc = 0.0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_corrects.double() / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_running_corrects = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_running_corrects += torch.sum(preds == labels.data)\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_running_corrects.double() / val_total\n",
        "    print(f\"Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Scheduler step\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    # Check for improvement\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        epochs_no_improve = 0\n",
        "        print(\"Validation accuracy improved, saving model.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement in val acc for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "    if epochs_no_improve == patience:\n",
        "        print(f\"Early stopping after {epoch+1} epochs.\")\n",
        "        break\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSp5eLQ0UPPG",
        "outputId": "2c46ed88-2d89-4e59-82fc-24713165212b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 2.0359 Acc: 0.5043\n",
            "Val Accuracy: 0.5469\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 2/20\n",
            "Train Loss: 1.6297 Acc: 0.6070\n",
            "Val Accuracy: 0.5953\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 3/20\n",
            "Train Loss: 1.3897 Acc: 0.6969\n",
            "Val Accuracy: 0.6391\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 4/20\n",
            "Train Loss: 1.2065 Acc: 0.7727\n",
            "Val Accuracy: 0.6516\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 5/20\n",
            "Train Loss: 1.0349 Acc: 0.8395\n",
            "Val Accuracy: 0.6609\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 6/20\n",
            "Train Loss: 0.9107 Acc: 0.8953\n",
            "Val Accuracy: 0.6656\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 7/20\n",
            "Train Loss: 0.8169 Acc: 0.9297\n",
            "Val Accuracy: 0.6531\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 8/20\n",
            "Train Loss: 0.7814 Acc: 0.9441\n",
            "Val Accuracy: 0.6719\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 9/20\n",
            "Train Loss: 0.7292 Acc: 0.9652\n",
            "Val Accuracy: 0.6672\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 10/20\n",
            "Train Loss: 0.7065 Acc: 0.9711\n",
            "Val Accuracy: 0.6734\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 11/20\n",
            "Train Loss: 0.6872 Acc: 0.9754\n",
            "Val Accuracy: 0.6828\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 12/20\n",
            "Train Loss: 0.6767 Acc: 0.9785\n",
            "Val Accuracy: 0.6766\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 13/20\n",
            "Train Loss: 0.6579 Acc: 0.9883\n",
            "Val Accuracy: 0.6766\n",
            "No improvement in val acc for 2 epoch(s).\n",
            "\n",
            "Epoch 14/20\n",
            "Train Loss: 0.6519 Acc: 0.9898\n",
            "Val Accuracy: 0.6828\n",
            "No improvement in val acc for 3 epoch(s).\n",
            "\n",
            "Epoch 15/20\n",
            "Train Loss: 0.6553 Acc: 0.9836\n",
            "Val Accuracy: 0.6844\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 16/20\n",
            "Train Loss: 0.6374 Acc: 0.9926\n",
            "Val Accuracy: 0.6891\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 17/20\n",
            "Train Loss: 0.6360 Acc: 0.9898\n",
            "Val Accuracy: 0.6844\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 18/20\n",
            "Train Loss: 0.6265 Acc: 0.9949\n",
            "Val Accuracy: 0.6906\n",
            "Validation accuracy improved, saving model.\n",
            "\n",
            "Epoch 19/20\n",
            "Train Loss: 0.6240 Acc: 0.9941\n",
            "Val Accuracy: 0.6797\n",
            "No improvement in val acc for 1 epoch(s).\n",
            "\n",
            "Epoch 20/20\n",
            "Train Loss: 0.6219 Acc: 0.9938\n",
            "Val Accuracy: 0.6766\n",
            "No improvement in val acc for 2 epoch(s).\n",
            "Best validation accuracy: 0.6906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'efficientnet_b3_rvl_cdip_small_200.pth')"
      ],
      "metadata": {
        "id": "VQy7BOElURZ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from torchvision.models import EfficientNet_B3_Weights # Import weights\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pretrained model architecture exactly like during training\n",
        "# Change efficientnet_b0 to efficientnet_b3 to match the saved model\n",
        "weights = EfficientNet_B3_Weights.DEFAULT # Define weights for the new model\n",
        "model = models.efficientnet_b3(weights=weights) # Load efficientnet_b3\n",
        "\n",
        "# Modify the classifier for 16 classes (must match training)\n",
        "num_classes = 16\n",
        "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "# Load your saved weights\n",
        "model.load_state_dict(torch.load('/content/efficientnet_b3_rvl_cdip_small_200.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the same transform as training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # convert grayscale to 3-channel\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Load and transform the image\n",
        "img_path = '/content/lengthy-itemised-hospital-bill-listing-every-item-used-and-cost-for-E0HCXN.jpg'\n",
        "# ensure image is in RGB format before applying the transform that expects 3 channels\n",
        "img = Image.open(img_path).convert('RGB')\n",
        "img_tensor = transform(img).unsqueeze(0).to(device)  # add batch dimension and move to device\n",
        "\n",
        "# Prediction\n",
        "with torch.no_grad():\n",
        "    outputs = model(img_tensor)\n",
        "    probabilities = F.softmax(outputs, dim=1)\n",
        "    top_p, top_class = probabilities.topk(3, dim=1)\n",
        "top_p = top_p.squeeze().tolist()\n",
        "top_class = top_class.squeeze().tolist()\n",
        "\n",
        "print(\"Top 3 Predicted Classes and Confidence Scores:\")\n",
        "for i in range(len(top_class)):\n",
        "    print(f\"Class Index: {top_class[i]}, Confidence: {top_p[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw1Qt51uZM9u",
        "outputId": "5479650b-b7dd-422c-b326-a8c8f95a6c15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Predicted Classes and Confidence Scores:\n",
            "Class Index: 6, Confidence: 0.2941\n",
            "Class Index: 1, Confidence: 0.1018\n",
            "Class Index: 0, Confidence: 0.0736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=\"/root/.cache/kagglehub/datasets/vaclavpechtor/rvl-cdip-small-200/versions/1/rvl-cdip-small-200/train\")\n",
        "print(train_dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejeNrLFbZbON",
        "outputId": "b8db013c-0236-4d21-9f96-233fccf54461"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'advertisement': 0, 'budget': 1, 'email': 2, 'file_folder': 3, 'form': 4, 'handwritten': 5, 'invoice': 6, 'letter': 7, 'memo': 8, 'news_article': 9, 'presentation': 10, 'questionnaire': 11, 'resume': 12, 'scientific_publication': 13, 'scientific_report': 14, 'specification': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_class = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
        "predicted_label = idx_to_class[top_class[0]]\n",
        "predicted_label_1 = idx_to_class[top_class[1]]\n",
        "predicted_label_2 = idx_to_class[top_class[2]]\n",
        "print(predicted_label)\n",
        "print(predicted_label_1)\n",
        "print(predicted_label_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlkRZSQ4Zy9d",
        "outputId": "8570cceb-5171-4090-c0be-f8611cc02e17"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "invoice\n",
            "budget\n",
            "advertisement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOVFpfSxZ5Ld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}